{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recognized-parcel",
   "metadata": {},
   "source": [
    "# Pratical Example: `california_housing`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-chain",
   "metadata": {},
   "source": [
    "## Normal equation (from linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rational-button",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phunc20/.config/miniconda3/envs/homl-1e/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/phunc20/.config/miniconda3/envs/homl-1e/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/phunc20/.config/miniconda3/envs/homl-1e/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/phunc20/.config/miniconda3/envs/homl-1e/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/phunc20/.config/miniconda3/envs/homl-1e/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/phunc20/.config/miniconda3/envs/homl-1e/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "regional-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape((-1,1)), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta_other = tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), tf.matmul(XT, y))\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value, theta_other_value = sess.run((theta, theta_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rising-float",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.6851040e+01],\n",
       "       [ 4.3711984e-01],\n",
       "       [ 9.4447248e-03],\n",
       "       [-1.0790110e-01],\n",
       "       [ 6.4765513e-01],\n",
       "       [-3.9395982e-06],\n",
       "       [-3.7892859e-03],\n",
       "       [-4.2037925e-01],\n",
       "       [-4.3349406e-01]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "million-starter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.6808594e+01],\n",
       "       [ 4.3722534e-01],\n",
       "       [ 9.4518661e-03],\n",
       "       [-1.0800934e-01],\n",
       "       [ 6.4801025e-01],\n",
       "       [-3.9152801e-06],\n",
       "       [-3.7903786e-03],\n",
       "       [-4.1992188e-01],\n",
       "       [-4.3298340e-01]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_other_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "brutal-marriage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(theta_other_value, theta_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rational-december",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.24461365e-02],\n",
       "       [ 1.05500221e-04],\n",
       "       [ 7.14138150e-06],\n",
       "       [-1.08242035e-04],\n",
       "       [ 3.55124474e-04],\n",
       "       [ 2.43180693e-08],\n",
       "       [-1.09267421e-06],\n",
       "       [ 4.57376242e-04],\n",
       "       [ 5.10662794e-04]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_other_value - theta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "conventional-particle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(theta_other_value, theta_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "loaded-iraqi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(theta_other_value, theta_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "smoking-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(theta_other_value, theta_value, rtol=1e-3, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "biblical-namibia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(theta_other_value, theta_value, rtol=1e-3, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "refined-kitchen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(theta_other_value, theta_value, rtol=1e-2, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lyric-pendant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-clinic",
   "metadata": {},
   "source": [
    "### `np.array_equal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "shared-landing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equiv(theta_other_value, theta_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "compatible-sheffield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function array_equal in module numpy:\n",
      "\n",
      "array_equal(a1, a2, equal_nan=False)\n",
      "    True if two arrays have the same shape and elements, False otherwise.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a1, a2 : array_like\n",
      "        Input arrays.\n",
      "    equal_nan : bool\n",
      "        Whether to compare NaN's as equal. If the dtype of a1 and a2 is\n",
      "        complex, values will be considered equal if either the real or the\n",
      "        imaginary component of a given value is ``nan``.\n",
      "    \n",
      "        .. versionadded:: 1.19.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    b : bool\n",
      "        Returns True if the arrays are equal.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    allclose: Returns True if two arrays are element-wise equal within a\n",
      "              tolerance.\n",
      "    array_equiv: Returns True if input arrays are shape consistent and all\n",
      "                 elements equal.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.array_equal([1, 2], [1, 2])\n",
      "    True\n",
      "    >>> np.array_equal(np.array([1, 2]), np.array([1, 2]))\n",
      "    True\n",
      "    >>> np.array_equal([1, 2], [1, 2, 3])\n",
      "    False\n",
      "    >>> np.array_equal([1, 2], [1, 4])\n",
      "    False\n",
      "    >>> a = np.array([1, np.nan])\n",
      "    >>> np.array_equal(a, a)\n",
      "    False\n",
      "    >>> np.array_equal(a, a, equal_nan=True)\n",
      "    True\n",
      "    \n",
      "    When ``equal_nan`` is True, complex values with nan components are\n",
      "    considered equal if either the real *or* the imaginary components are nan.\n",
      "    \n",
      "    >>> a = np.array([1 + 1j])\n",
      "    >>> b = a.copy()\n",
      "    >>> a.real = np.nan\n",
      "    >>> b.imag = np.nan\n",
      "    >>> np.array_equal(a, b, equal_nan=True)\n",
      "    True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.array_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "armed-conversation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function array_equiv in module numpy:\n",
      "\n",
      "array_equiv(a1, a2)\n",
      "    Returns True if input arrays are shape consistent and all elements equal.\n",
      "    \n",
      "    Shape consistent means they are either the same shape, or one input array\n",
      "    can be broadcasted to create the same shape as the other one.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a1, a2 : array_like\n",
      "        Input arrays.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : bool\n",
      "        True if equivalent, False otherwise.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.array_equiv([1, 2], [1, 2])\n",
      "    True\n",
      "    >>> np.array_equiv([1, 2], [1, 3])\n",
      "    False\n",
      "    \n",
      "    Showing the shape equivalence:\n",
      "    \n",
      "    >>> np.array_equiv([1, 2], [[1, 2], [1, 2]])\n",
      "    True\n",
      "    >>> np.array_equiv([1, 2], [[1, 2, 1, 2], [1, 2, 1, 2]])\n",
      "    False\n",
      "    \n",
      "    >>> np.array_equiv([1, 2], [[1, 2], [1, 3]])\n",
      "    False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.array_equiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cellular-consultation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function allclose in module numpy:\n",
      "\n",
      "allclose(a, b, rtol=1e-05, atol=1e-08, equal_nan=False)\n",
      "    Returns True if two arrays are element-wise equal within a tolerance.\n",
      "    \n",
      "    The tolerance values are positive, typically very small numbers.  The\n",
      "    relative difference (`rtol` * abs(`b`)) and the absolute difference\n",
      "    `atol` are added together to compare against the absolute difference\n",
      "    between `a` and `b`.\n",
      "    \n",
      "    NaNs are treated as equal if they are in the same place and if\n",
      "    ``equal_nan=True``.  Infs are treated as equal if they are in the same\n",
      "    place and of the same sign in both arrays.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a, b : array_like\n",
      "        Input arrays to compare.\n",
      "    rtol : float\n",
      "        The relative tolerance parameter (see Notes).\n",
      "    atol : float\n",
      "        The absolute tolerance parameter (see Notes).\n",
      "    equal_nan : bool\n",
      "        Whether to compare NaN's as equal.  If True, NaN's in `a` will be\n",
      "        considered equal to NaN's in `b` in the output array.\n",
      "    \n",
      "        .. versionadded:: 1.10.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    allclose : bool\n",
      "        Returns True if the two arrays are equal within the given\n",
      "        tolerance; False otherwise.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    isclose, all, any, equal\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    If the following equation is element-wise True, then allclose returns\n",
      "    True.\n",
      "    \n",
      "     absolute(`a` - `b`) <= (`atol` + `rtol` * absolute(`b`))\n",
      "    \n",
      "    The above equation is not symmetric in `a` and `b`, so that\n",
      "    ``allclose(a, b)`` might be different from ``allclose(b, a)`` in\n",
      "    some rare cases.\n",
      "    \n",
      "    The comparison of `a` and `b` uses standard broadcasting, which\n",
      "    means that `a` and `b` need not have the same shape in order for\n",
      "    ``allclose(a, b)`` to evaluate to True.  The same is true for\n",
      "    `equal` but not `array_equal`.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.allclose([1e10,1e-7], [1.00001e10,1e-8])\n",
      "    False\n",
      "    >>> np.allclose([1e10,1e-8], [1.00001e10,1e-9])\n",
      "    True\n",
      "    >>> np.allclose([1e10,1e-8], [1.0001e10,1e-9])\n",
      "    False\n",
      "    >>> np.allclose([1.0, np.nan], [1.0, np.nan])\n",
      "    False\n",
      "    >>> np.allclose([1.0, np.nan], [1.0, np.nan], equal_nan=True)\n",
      "    True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.allclose)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "racial-plymouth",
   "metadata": {},
   "source": [
    "absolute(`a` - `b`) <= (`atol` + `rtol` * absolute(`b`))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-broadcasting",
   "metadata": {},
   "source": [
    "## Gradient descent manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-facial",
   "metadata": {},
   "source": [
    "### w/o normalizing the data\n",
    "**(?1)** Do we need `tf.reset_default_graph()` to avoid mixing together what we are about to do with what we just did?<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "square-obligation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch 0000) MSE = 12344782906982400.0000\n",
      "(epoch 0100) MSE = nan\n",
      "(epoch 0200) MSE = nan\n",
      "(epoch 0300) MSE = nan\n",
      "(epoch 0400) MSE = nan\n",
      "(epoch 0500) MSE = nan\n",
      "(epoch 0600) MSE = nan\n",
      "(epoch 0700) MSE = nan\n",
      "(epoch 0800) MSE = nan\n",
      "(epoch 0900) MSE = nan\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "        if epoch % 100 == 0:\n",
    "            #print(f\"(epoch {epoch:04d}) MSE = {sess.run(mse):.4f}\")\n",
    "            print(f\"(epoch {epoch:04d}) MSE = {mse.eval():.4f}\")\n",
    "    \n",
    "    final_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-blowing",
   "metadata": {},
   "source": [
    "**(?2)** The MSE is not decreasing. What's happened?<br>\n",
    "Is it because we should have done a `tf.reset_default_graph()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "difficult-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "urban-replication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch 0000) MSE = 296842369695744.0000\n",
      "(epoch 0100) MSE = nan\n",
      "(epoch 0200) MSE = nan\n",
      "(epoch 0300) MSE = nan\n",
      "(epoch 0400) MSE = nan\n",
      "(epoch 0500) MSE = nan\n",
      "(epoch 0600) MSE = nan\n",
      "(epoch 0700) MSE = nan\n",
      "(epoch 0800) MSE = nan\n",
      "(epoch 0900) MSE = nan\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "        if epoch % 100 == 0:\n",
    "            #print(f\"(epoch {epoch:04d}) MSE = {sess.run(mse):.4f}\")\n",
    "            print(f\"(epoch {epoch:04d}) MSE = {mse.eval():.4f}\")\n",
    "    \n",
    "    final_theta = theta.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-funds",
   "metadata": {},
   "source": [
    "I've double-checked: There seems to be no typo in the code, at least no significant diff from the code in the book. Was it due to lack of normalization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-infrared",
   "metadata": {},
   "source": [
    "### w/ data normalized\n",
    "- `sklearn`\n",
    "- `tf`\n",
    "- `np`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "constitutional-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "royal-cigarette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch 0000) MSE = 9.2645\n",
      "(epoch 0100) MSE = 0.7652\n",
      "(epoch 0200) MSE = 0.5963\n",
      "(epoch 0300) MSE = 0.5749\n",
      "(epoch 0400) MSE = 0.5612\n",
      "(epoch 0500) MSE = 0.5513\n",
      "(epoch 0600) MSE = 0.5441\n",
      "(epoch 0700) MSE = 0.5388\n",
      "(epoch 0800) MSE = 0.5350\n",
      "(epoch 0900) MSE = 0.5322\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "        if epoch % 100 == 0:\n",
    "            #print(f\"(epoch {epoch:04d}) MSE = {sess.run(mse):.4f}\")\n",
    "            print(f\"(epoch {epoch:04d}) MSE = {mse.eval():.4f}\")\n",
    "    \n",
    "    final_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-andrews",
   "metadata": {},
   "source": [
    "**(R2)** Yes, it seems that normalizing the data in this case is of crucial importance.\n",
    "\n",
    "**(?3)** In the book (p.237 on top) it says that training w/o first normalizing the data only slows down the training. Let's train the unnormalized data with a prolonged `n_epochs`, say `10_000`, to see if that is true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "architectural-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch 0000) MSE = 183866895630336.0000\n",
      "(epoch 0100) MSE = nan\n",
      "(epoch 0200) MSE = nan\n",
      "(epoch 0300) MSE = nan\n",
      "(epoch 0400) MSE = nan\n",
      "(epoch 0500) MSE = nan\n",
      "(epoch 0600) MSE = nan\n",
      "(epoch 0700) MSE = nan\n",
      "(epoch 0800) MSE = nan\n",
      "(epoch 0900) MSE = nan\n",
      "(epoch 1000) MSE = nan\n",
      "(epoch 1100) MSE = nan\n",
      "(epoch 1200) MSE = nan\n",
      "(epoch 1300) MSE = nan\n",
      "(epoch 1400) MSE = nan\n",
      "(epoch 1500) MSE = nan\n",
      "(epoch 1600) MSE = nan\n",
      "(epoch 1700) MSE = nan\n",
      "(epoch 1800) MSE = nan\n",
      "(epoch 1900) MSE = nan\n",
      "(epoch 2000) MSE = nan\n",
      "(epoch 2100) MSE = nan\n",
      "(epoch 2200) MSE = nan\n",
      "(epoch 2300) MSE = nan\n",
      "(epoch 2400) MSE = nan\n",
      "(epoch 2500) MSE = nan\n",
      "(epoch 2600) MSE = nan\n",
      "(epoch 2700) MSE = nan\n",
      "(epoch 2800) MSE = nan\n",
      "(epoch 2900) MSE = nan\n",
      "(epoch 3000) MSE = nan\n",
      "(epoch 3100) MSE = nan\n",
      "(epoch 3200) MSE = nan\n",
      "(epoch 3300) MSE = nan\n",
      "(epoch 3400) MSE = nan\n",
      "(epoch 3500) MSE = nan\n",
      "(epoch 3600) MSE = nan\n",
      "(epoch 3700) MSE = nan\n",
      "(epoch 3800) MSE = nan\n",
      "(epoch 3900) MSE = nan\n",
      "(epoch 4000) MSE = nan\n",
      "(epoch 4100) MSE = nan\n",
      "(epoch 4200) MSE = nan\n",
      "(epoch 4300) MSE = nan\n",
      "(epoch 4400) MSE = nan\n",
      "(epoch 4500) MSE = nan\n",
      "(epoch 4600) MSE = nan\n",
      "(epoch 4700) MSE = nan\n",
      "(epoch 4800) MSE = nan\n",
      "(epoch 4900) MSE = nan\n",
      "(epoch 5000) MSE = nan\n",
      "(epoch 5100) MSE = nan\n",
      "(epoch 5200) MSE = nan\n",
      "(epoch 5300) MSE = nan\n",
      "(epoch 5400) MSE = nan\n",
      "(epoch 5500) MSE = nan\n",
      "(epoch 5600) MSE = nan\n",
      "(epoch 5700) MSE = nan\n",
      "(epoch 5800) MSE = nan\n",
      "(epoch 5900) MSE = nan\n",
      "(epoch 6000) MSE = nan\n",
      "(epoch 6100) MSE = nan\n",
      "(epoch 6200) MSE = nan\n",
      "(epoch 6300) MSE = nan\n",
      "(epoch 6400) MSE = nan\n",
      "(epoch 6500) MSE = nan\n",
      "(epoch 6600) MSE = nan\n",
      "(epoch 6700) MSE = nan\n",
      "(epoch 6800) MSE = nan\n",
      "(epoch 6900) MSE = nan\n",
      "(epoch 7000) MSE = nan\n",
      "(epoch 7100) MSE = nan\n",
      "(epoch 7200) MSE = nan\n",
      "(epoch 7300) MSE = nan\n",
      "(epoch 7400) MSE = nan\n",
      "(epoch 7500) MSE = nan\n",
      "(epoch 7600) MSE = nan\n",
      "(epoch 7700) MSE = nan\n",
      "(epoch 7800) MSE = nan\n",
      "(epoch 7900) MSE = nan\n",
      "(epoch 8000) MSE = nan\n",
      "(epoch 8100) MSE = nan\n",
      "(epoch 8200) MSE = nan\n",
      "(epoch 8300) MSE = nan\n",
      "(epoch 8400) MSE = nan\n",
      "(epoch 8500) MSE = nan\n",
      "(epoch 8600) MSE = nan\n",
      "(epoch 8700) MSE = nan\n",
      "(epoch 8800) MSE = nan\n",
      "(epoch 8900) MSE = nan\n",
      "(epoch 9000) MSE = nan\n",
      "(epoch 9100) MSE = nan\n",
      "(epoch 9200) MSE = nan\n",
      "(epoch 9300) MSE = nan\n",
      "(epoch 9400) MSE = nan\n",
      "(epoch 9500) MSE = nan\n",
      "(epoch 9600) MSE = nan\n",
      "(epoch 9700) MSE = nan\n",
      "(epoch 9800) MSE = nan\n",
      "(epoch 9900) MSE = nan\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 10_000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "        if epoch % 100 == 0:\n",
    "            #print(f\"(epoch {epoch:04d}) MSE = {sess.run(mse):.4f}\")\n",
    "            print(f\"(epoch {epoch:04d}) MSE = {mse.eval():.4f}\")\n",
    "    \n",
    "    final_theta = theta.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-diameter",
   "metadata": {},
   "source": [
    "I even tried `n_epochs = 100_000`, we still get `MSE = nan` right after the first iteration. **(R3)** It seems that no normalization not only slows down the training, but sometimes it won't lead to a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-panel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-things",
   "metadata": {},
   "source": [
    "Don't forget that we still need to verify the validity of the formula `gradients = 2/m * tf.matmul(tf.transpose(X), error)`\n",
    "\n",
    "- `theta.shape` equals `(n+1, 1)`\n",
    "  - For `gradients` to be correct, at least `gradients.shape` should be **the same**: `error.shape` equals `(m, 1)`, `X.shape` being `(m, n+1)` $\\implies$ `tf.matmul(tf.transpose(X), error)` equal to `(n+1, 1)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-stage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-marine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-richards",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
