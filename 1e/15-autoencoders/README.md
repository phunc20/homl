### Motivation
The **_hailstone sequence_** from the author tries to give us an explanation/motivation as to why
autoencoders work. Putting in other words, it may be easy for computers to memorize very long
sequence, so we increase the difficulty to force it to feel the need to find patterns, just like
the hailstone sequence for us.

autoencoder should probably be translated in Chinese as 自己encoder, i.e. reflecting the fact that
its input and output should be highly similar if not identical.

### PCA and Undercomplete Linear Autoencoder
**(?1)** Prove
- either numerically
- or mathematically
that
> if the autoencoder uses only linear activations (i.e. **no activations**) and the cost function is the MSE, then it ends up performing Principal Component Analysis.





