{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e026daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4253806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/phunc20/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/phunc20/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data()\n",
    "X_train[0][:10]  # the 1st review, its first 10 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e438a",
   "metadata": {},
   "source": [
    "**(?)** How to get rid of the `VisibleDeprecationWarning`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de1ed5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data = keras.datasets.imdb.load_data()\n",
    "type(imdb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3612811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imdb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9a68c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'tuple'> 2\n",
      "1 <class 'tuple'> 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(i, type(imdb_data[i]), len(imdb_data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56733941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "1 <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(i, type(imdb_data[0][i]), type(imdb_data[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0ba104a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (25000,) (25000,)\n",
      "1 (25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(i, imdb_data[1][i].shape, imdb_data[1][i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551c3e2c",
   "metadata": {},
   "source": [
    "## Decode a Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "921c14c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "type(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2759b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c07cda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 4223)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index[\"movie\"], word_index[\"montage\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c0e405",
   "metadata": {},
   "source": [
    "`word_index` is a dictionary whose keys are words (i.e. strings) and whose values are the encoded indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20c21d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_to_word is a dictionary being nearly the opposite of word_index\n",
    "id_to_word = {index + 3: word for word, index in word_index.items()}\n",
    "for id_, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    id_to_word[id_] = token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29faf294",
   "metadata": {},
   "source": [
    "**(?)** Why `index + 3`?<br>\n",
    "**(R)** Note the diff btw two entities\n",
    "\n",
    "01. `index`\n",
    "  - `index` is what `keras.datasets.imdb.get_word_index()` gave us.\n",
    "02. `id_`\n",
    "  - `id_` is index shifted to the right by 3 integers to allow spaces for the 3 special tokens `\"<pad>\", \"<sos>\", \"<unk>\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa5631bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> this film was just brilliant casting location scenery story'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_review = \" \".join([id_to_word[id_] for id_ in X_train[0][:10]])\n",
    "example_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3bd305",
   "metadata": {},
   "source": [
    "```python\n",
    "[word_index[word]+3 for word in example_review.split(\" \")]\n",
    "```\n",
    "<br>\n",
    "\n",
    "```\n",
    "KeyError: '<sos>'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f4b5662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]\n",
      "[14, 22, 16, 43, 530, 973, 1622, 1385, 65]\n"
     ]
    }
   ],
   "source": [
    "word_to_id = {word: id_ for id_, word in id_to_word.items()}\n",
    "print([word_to_id[word] for word in example_review.split(\" \")])\n",
    "print(X_train[0][:10])\n",
    "print([word_index[word]+3 for word in\n",
    "\"this film was just brilliant casting location scenery story\".split(\" \")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea89b60",
   "metadata": {},
   "source": [
    "Let's handle the preprocessing exclusively in tensorflow, so that the entiring processing is inside the model and thus can be shifted outside Python, to mobile devices and web browsers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1a2050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9f8dc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /home/phunc20/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969fe0fc28d14c93a2cc524b94e5073b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d550fce700474f2d8f7d471535600c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /home/phunc20/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incomplete80KGZZ/imdb_reviews-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed91bfb421f42be96fc550a3dfa8b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /home/phunc20/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incomplete80KGZZ/imdb_reviews-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4562376da86d40f7999a2cf5dd19af44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /home/phunc20/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incomplete80KGZZ/imdb_reviews-unsupervised.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97b6c8883104731a2109ed5d1236b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to /home/phunc20/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(dict, tensorflow_datasets.core.dataset_info.DatasetInfo)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
    "type(datasets), type(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38a94540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eba026dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.int64)>,\n",
       " 'train': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.int64)>,\n",
       " 'unsupervised': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.int64)>}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "297584f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = info.splits[\"train\"].num_examples\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27fa78a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X_batch, y_batch):\n",
    "    X_batch = tf.strings.substr(X_batch, 0, 300)\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"<br\\\\s*/?>\", b\" \")\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \")\n",
    "    X_batch = tf.strings.split(X_batch)\n",
    "    return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970a2e8",
   "metadata": {},
   "source": [
    "**(?)** Try to dig deeper into why the choices of these functions such as `tf.strings.substr`, etc. In particular, what kind of form does the `X_batch` take before entering this function of `preprocess`?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1d9d1b9",
   "metadata": {},
   "source": [
    "next(datasets[\"train\"].batch(32))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e8a34cff",
   "metadata": {},
   "source": [
    "TypeError: 'BatchDataset' object is not an iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "334d85de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(datasets[\"train\"].batch(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84219b26",
   "metadata": {},
   "source": [
    "**(?)** We are not modifying `y_batch`. Why not just use input arg `X_batch` and return `X_batch` alone?<br>\n",
    "**(R)** Later on, there will be a line of code\n",
    "```python\n",
    "for X_batch, y_batch in datasets[\"train\"].batch(32).map(preprocess):\n",
    "```\n",
    "This line shows how we would like to use our function `preprocess` and also the reason why it cannot be a function of `X_batch` alone (i.e. must include `y_batch` as input arg as well.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcd3eb6",
   "metadata": {},
   "source": [
    "### Construct the vocabulary\n",
    "01. going thru the whole training set\n",
    "02. applying our `preprocess()` function\n",
    "03. using a `Counter` (in `collections` module) to count the number of occurrences of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8df8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "vocabulary = Counter()\n",
    "for X_batch, y_batch in datasets[\"train\"].batch(32).map(preprocess):\n",
    "    for review in X_batch:\n",
    "        vocabulary.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e42070",
   "metadata": {},
   "source": [
    "**(?)** Try to understand and explain the convoluted line `vocabulary.update(list(review.numpy()))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f95d5749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'<pad>', 214309), (b'the', 61137), (b'a', 38564)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_common()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f5119",
   "metadata": {},
   "source": [
    "As expected, there should be a lot of `\"<pad>\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f582282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
