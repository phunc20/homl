{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe432a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca955fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://homl.info/shakespeare\n",
      "1122304/1115394 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/phunc20/.keras/datasets/shakespeare.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_url = \"https://homl.info/shakespeare\"  # shortcut URL\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c17603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nA'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()\n",
    "\n",
    "shakespeare_text[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "690c4f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x7f077b183dd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "018e1457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit_on_texts in module keras_preprocessing.text:\n",
      "\n",
      "fit_on_texts(texts) method of keras_preprocessing.text.Tokenizer instance\n",
      "    Updates internal vocabulary based on a list of texts.\n",
      "    \n",
      "    In the case where texts contains lists,\n",
      "    we assume each entry of the lists to be a token.\n",
      "    \n",
      "    Required before using `texts_to_sequences` or `texts_to_matrix`.\n",
      "    \n",
      "    # Arguments\n",
      "        texts: can be a list of strings,\n",
      "            a generator of strings (for memory-efficiency),\n",
      "            or a list of list of strings.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tokenizer.fit_on_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3625a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would happen if we forgot its arg has to be a list?\n",
    "tokenizer.fit_on_texts(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28898c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"First\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ed4f62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20], [6], [9], [8], [3]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(\"First\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "469072c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F', 'i', 'r', 's', 't']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = list(\"First\")\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7672a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20], [6], [9], [8], [3]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7372b56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['F', 'i', 'r', 's', 't']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7da4b62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69ad357b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f i r s t']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79572694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f', 'i', 'r', 's', 't']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20], [6], [9], [8], [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e30c900a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_id = len(tokenizer.word_index)\n",
    "max_id  # num of distinct characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dd5778b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"  e t o a i h s r n \\n l d u m y w , c f g b p : k v . ' ; ? ! - j q x z 3 & $\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([range(1, max_id+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66e127b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = tokenizer.document_count\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e99490c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e161dfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50a7b18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[0]])[0] == ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74313772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54580434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  5,  8, ..., 20, 26, 10])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map each letter to its ID (0-38 instead of 1-39)\n",
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da7117e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6a7079c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003854"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = dataset_size * 90 // 100\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f0a6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4115cd2c",
   "metadata": {},
   "source": [
    "## Chopping the Sequential Dataset into Multiple Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7feaa7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1  # target = input shifted 1 character ahead\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c523534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(19, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(18, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "ds_just_flat = dataset.flat_map(lambda ds: ds)\n",
    "for i, tensor in enumerate(ds_just_flat):\n",
    "    if i < 10:\n",
    "        print(tensor)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "830cc62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda ds: ds.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09c96805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101,)\n",
      "(101,)\n",
      "(101,)\n",
      "(101,)\n",
      "(101,)\n",
      "(101,)\n",
      "(101,)\n",
      "(101,)\n",
      "(101,)\n",
      "(101,)\n"
     ]
    }
   ],
   "source": [
    "for i, tensor in enumerate(dataset):\n",
    "    if i < 10:\n",
    "        print(tensor.shape)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa28fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10_000).batch(batch_size)\n",
    "# Recall that the arg inside shuffle() is the buffer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7aed5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[26 10 10 ...  1 26 10]\n",
      " [ 2  6  3 ...  1 26 10]\n",
      " [ 0  3  9 ... 26 10 10]\n",
      " ...\n",
      " [13  8  0 ...  0  6  5]\n",
      " [ 3 11  1 ...  2  6  1]\n",
      " [35  1  9 ... 10 16  6]], shape=(32, 101), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[17  0 16 ...  1  0 16]\n",
      " [ 8  9  0 ...  9 12  0]\n",
      " [20  1  9 ...  8  9  7]\n",
      " ...\n",
      " [ 3 14 22 ...  0 15  3]\n",
      " [ 7  1  0 ...  5  9  0]\n",
      " [ 5  9  7 ...  5  9 12]], shape=(32, 101), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ 0  6  1 ...  0 22  1]\n",
      " [ 2  3  9 ...  1  0 12]\n",
      " [ 8  9  7 ...  7  0  2]\n",
      " ...\n",
      " [ 3  9  7 ...  5 18  1]\n",
      " [13  7  0 ... 11 11  0]\n",
      " [ 5  2  6 ... 16  6  4]], shape=(32, 101), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataset):\n",
    "    if i < 3:\n",
    "        print(batch)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a3c5011",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda batch: (batch[:, :-1], batch[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56ba75fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'> 2 (32, 100) (32, 100)\n",
      "<class 'tuple'> 2 (32, 100) (32, 100)\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataset):\n",
    "    if i < 2:\n",
    "        print(type(batch), len(batch), batch[0].shape, batch[1].shape)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c725b4",
   "metadata": {},
   "source": [
    "**(?)** Why the target is a tensor of length `100`, not a single character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08a5f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda X_batch, Y_batch:\n",
    "                      (tf.one_hot(X_batch, depth=max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3665e0f7",
   "metadata": {},
   "source": [
    "Let's make sure the correctness of `tf.one_hot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c283f83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 100), dtype=int32, numpy=\n",
       "array([[18,  2,  0, ..., 34, 28, 10],\n",
       "       [11, 34,  6, ..., 25, 11,  3],\n",
       "       [28, 23, 31, ..., 28, 35,  2],\n",
       "       ...,\n",
       "       [30, 34,  0, ..., 14, 32, 35],\n",
       "       [18, 27, 26, ...,  9,  8, 19],\n",
       "       [ 6, 31, 32, ...,  0, 16,  8]], dtype=int32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform(maxval=max_id-1, dtype=tf.int32, shape=(32,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a48ea21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 100, 39), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch = tf.random.uniform(maxval=max_id-1, dtype=tf.int32, shape=(32,100))\n",
    "one_hotted = tf.one_hot(X_batch, depth=max_id)\n",
    "one_hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "69331c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumsum\n",
      "cumulative_logsumexp\n",
      "reduce_logsumexp\n",
      "reduce_sum\n",
      "segment_sum\n",
      "unsorted_segment_sum\n"
     ]
    }
   ],
   "source": [
    "for f in dir(tf.math):\n",
    "    if \"sum\" in f:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "659af6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reduce_sum in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "reduce_sum(input_tensor, axis=None, keepdims=False, name=None)\n",
      "    Computes the sum of elements across dimensions of a tensor.\n",
      "    \n",
      "    Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "    Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "    of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "    reduced dimensions are retained with length 1.\n",
      "    \n",
      "    If `axis` is None, all dimensions are reduced, and a\n",
      "    tensor with a single element is returned.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    >>> # x has a shape of (2, 3) (two rows and three columns):\n",
      "    >>> x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
      "    >>> x.numpy()\n",
      "    array([[1, 1, 1],\n",
      "           [1, 1, 1]], dtype=int32)\n",
      "    >>> # sum all the elements\n",
      "    >>> # 1 + 1 + 1 + 1 + 1+ 1 = 6\n",
      "    >>> tf.reduce_sum(x).numpy()\n",
      "    6\n",
      "    >>> # reduce along the first dimension\n",
      "    >>> # the result is [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
      "    >>> tf.reduce_sum(x, 0).numpy()\n",
      "    array([2, 2, 2], dtype=int32)\n",
      "    >>> # reduce along the second dimension\n",
      "    >>> # the result is [1, 1] + [1, 1] + [1, 1] = [3, 3]\n",
      "    >>> tf.reduce_sum(x, 1).numpy()\n",
      "    array([3, 3], dtype=int32)\n",
      "    >>> # keep the original dimensions\n",
      "    >>> tf.reduce_sum(x, 1, keepdims=True).numpy()\n",
      "    array([[3],\n",
      "           [3]], dtype=int32)\n",
      "    >>> # reduce along both dimensions\n",
      "    >>> # the result is 1 + 1 + 1 + 1 + 1 + 1 = 6\n",
      "    >>> # or, equivalently, reduce along rows, then reduce the resultant array\n",
      "    >>> # [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
      "    >>> # 2 + 2 + 2 = 6\n",
      "    >>> tf.reduce_sum(x, [0, 1]).numpy()\n",
      "    6\n",
      "    \n",
      "    \n",
      "    Args:\n",
      "      input_tensor: The tensor to reduce. Should have numeric type.\n",
      "      axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "        dimensions. Must be in the range `[-rank(input_tensor),\n",
      "        rank(input_tensor)]`.\n",
      "      keepdims: If true, retains reduced dimensions with length 1.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      The reduced tensor, of the same dtype as the input_tensor.\n",
      "    \n",
      "    @compatibility(numpy)\n",
      "    Equivalent to np.sum apart the fact that numpy upcast uint8 and int32 to\n",
      "    int64 while tensorflow returns the same dtype as the input.\n",
      "    @end_compatibility\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.math.reduce_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a0be64b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 100), dtype=float32, numpy=\n",
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_sum(one_hotted, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4079e3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3200.0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_sum(one_hotted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "87350cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff1defb",
   "metadata": {},
   "source": [
    "## Building and Training the Char-Rnn Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e87bd7c",
   "metadata": {},
   "source": [
    "**(?)** Why use `sparse_categorical_crossentropy`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d309a359",
   "metadata": {},
   "source": [
    "**(?)** `GRU` with `128` units. What that really mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbb6a9e",
   "metadata": {},
   "source": [
    "**(?)** The meaning of `dropout` and `recurrent_dropout` in `keras.layers.GRU()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "de1432f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "     75/Unknown - 30s 310ms/step - loss: 3.2848"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-4c40e07f28be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m ])\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\")),\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc30388",
   "metadata": {},
   "source": [
    "## Using the Char-RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed1c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(keras)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
