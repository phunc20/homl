{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0a5d0a",
   "metadata": {},
   "source": [
    "## Clarification of A Recurrent Neuron and A Layer of Recurrent Neurons\n",
    "Actually the figures `15-1` and `15-2` expresses quite accurately what each vector's dimension is, namely when it is **not boldface**,\n",
    "it concerns a **scalar** (like the $y, y_{(t-3)}\\,, y_{(t-2)}\\,, y_{(t-1)}\\,, y_{(t)}$ in figure `15-1`.) And when it is **boldface**,\n",
    "it concerns a **vector** (like the $\\mathbf{y}, \\mathbf{y}_{(0)}\\,, \\mathbf{y}_{(1)}\\,, \\mathbf{y}_{(2)}$ in figure `15-2`.)\n",
    "![](./figs/fig.15-1.png)\n",
    "![](./figs/fig.15-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4af21e",
   "metadata": {},
   "source": [
    "More explicitly speaking,\n",
    "\n",
    "- a (recurrent) neuron's output is always a **scalar**\n",
    "- a layer of recurrent neurons is a cooperative unit of multiple recurrent neurons. And its output is a **vector**, whose dimension equals the number of neurons in the layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb728a",
   "metadata": {},
   "source": [
    "## Recurrent Neuron\n",
    "We have\n",
    "\n",
    "- $y_{(t)} \\in \\mathbb{R}$ for all time $t$\n",
    "- $\\mathbf{x}_{(t)} \\in \\mathbb{R}^{n_{\\,\\text{inputs}}}\\;\\;$ for all time $t$, where ${n_{\\,\\text{inputs}}}$ stands for the number of input neurons\n",
    "- A single neuron's parameters are vectors $\\mathbf{w_x} \\in \\mathbb{R}^{n_{\\,\\text{inputs}}}\\;\\;$ and scalars $w_y \\in \\mathbb{R}, b \\in \\mathbb{R}$\n",
    "- An activation function $\\phi$\n",
    "- The formula connecting all these together is $$y_{(t)} = \\phi\\left(\\mathbf{w_x} \\cdot \\mathbf{x}_{(t)} + w_y y_{(t-1)} + b\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f88d1e",
   "metadata": {},
   "source": [
    "## A Layer of Recurrent Neurons (To be edited!!!)\n",
    "We have\n",
    "\n",
    "For a single sequence,\n",
    "\n",
    "- $\\mathbf{y}_{(t)} \\in \\mathbb{R}^{n_{\\,\\text{outputs}}}\\;\\;\\;$ for all time $t$, where ${n_{\\,\\text{outputs}}}$ stands for the number of output neurons\n",
    "  - Initially, $\\mathbf{y}_{(0)} = \\mathbf{0}$\n",
    "  - For convenience, we denote $k = n_{\\,\\text{outputs}}$ so that $\\mathbf{y}_{(t)} \\in \\mathbb{R}^k$\n",
    "- $\\mathbf{x}_{(t)} \\in \\mathbb{R}^{n_{\\,\\text{inputs}}}\\;\\;$ for all time $t$\n",
    "  - For convenience, we denote $n = n_{\\,\\text{inputs}}$ so that $\\mathbf{x}_{(t)} \\in \\mathbb{R}^n$\n",
    "- Trainable parameters: Matrices $\\hat{W}_{\\mathbf{x}} \\in M_{k \\times n}, \\hat{W}_{\\mathbf{y}} \\in M_{k \\times k}\\;\\;$ and vector $\\hat{\\mathbf{b}} \\in \\mathbb{R}^k$\n",
    "  - The reason for putting the hats will be made clear below\n",
    "- An activation function $\\phi$\n",
    "- The formula connecting all these together is $$\\mathbf{y}_{(t)} = \\phi\\left(\\hat{W}_{\\mathbf{x}}\\, \\mathbf{x} + \\hat{W}_{\\mathbf{y}}\\, \\mathbf{y} + \\hat{\\mathbf{b}}\\right)$$\n",
    "  - The activation $\\phi$ simply acts component by component\n",
    "\n",
    "For a batch of sequences,\n",
    "\n",
    "- Let $\\beta$ be the batch size\n",
    "- $\\mathbf{y}_{(t)}^{(j)} \\in \\mathbb{R}^{k}$ for all time $t$ and for all batch instance $j$\n",
    "  - $Y_{(t)} \\in \\mathbb{R}^{kk}$ (TODO)\n",
    "- $\\mathbf{x}_{(t)}^{(j)} \\in \\mathbb{R}^{n}$ for all time $t$ and for all batch instance $j$\n",
    "  - $X_{(t)} \\in \\mathbb{R}^{}$ (TODO)\n",
    "- Trainable parameters: Matrices $W_{\\mathbf{x}} := \\hat{W}_{\\mathbf{x}}^{T}, W_{\\mathbf{y}} := \\hat{W}_{\\mathbf{y}}^{T}$ and vector $\\mathbf{b} := \\hat{\\mathbf{b}}^{T}$\n",
    "  - The reader has probably seen why we had put a hat on the variables earlier\n",
    "- An activation function $\\phi$\n",
    "- The formula connecting all these together is $$Y_{(t)}= \\phi\\left(X_{(t)} W_{\\mathbf{x}} + Y_{(t-1)} W_{\\mathbf{y}} + b\\right)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a0bb45",
   "metadata": {},
   "source": [
    "### Number of Trainable Parameters\n",
    "If our understanding above is correct, then with\n",
    "$$W_{\\mathbf{x}} \\in M_{n \\times k}, W_{\\mathbf{y}} \\in M_{k \\times k}, \\mathbf{b} \\in \\mathbb{R}^k$$\n",
    "`(# params) = n*k + k*k + k`.\n",
    "\n",
    "Let's verify whether this is true in `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef0cd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-13 10:38:43.173593: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-13 10:38:43.173632: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f69f5b53",
   "metadata": {},
   "source": [
    "help(keras.layers.SimpleRNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "905e6d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 11\n",
    "k = 5\n",
    "simpleRNN_layer = keras.layers.SimpleRNN(k, input_shape=(None, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117f90ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['activation',\n",
       " 'activity_regularizer',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_update',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'apply',\n",
       " 'bias_constraint',\n",
       " 'bias_initializer',\n",
       " 'bias_regularizer',\n",
       " 'build',\n",
       " 'built',\n",
       " 'call',\n",
       " 'cell',\n",
       " 'compute_dtype',\n",
       " 'compute_mask',\n",
       " 'compute_output_shape',\n",
       " 'compute_output_signature',\n",
       " 'constants_spec',\n",
       " 'count_params',\n",
       " 'dropout',\n",
       " 'dtype',\n",
       " 'dtype_policy',\n",
       " 'dynamic',\n",
       " 'finalize_state',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_initial_state',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_losses_for',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_updates_for',\n",
       " 'get_weights',\n",
       " 'go_backwards',\n",
       " 'inbound_nodes',\n",
       " 'input',\n",
       " 'input_mask',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'kernel_constraint',\n",
       " 'kernel_initializer',\n",
       " 'kernel_regularizer',\n",
       " 'losses',\n",
       " 'metrics',\n",
       " 'name',\n",
       " 'name_scope',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'outbound_nodes',\n",
       " 'output',\n",
       " 'output_mask',\n",
       " 'output_shape',\n",
       " 'recurrent_constraint',\n",
       " 'recurrent_dropout',\n",
       " 'recurrent_initializer',\n",
       " 'recurrent_regularizer',\n",
       " 'reset_states',\n",
       " 'return_sequences',\n",
       " 'return_state',\n",
       " 'set_weights',\n",
       " 'state_spec',\n",
       " 'stateful',\n",
       " 'states',\n",
       " 'submodules',\n",
       " 'supports_masking',\n",
       " 'time_major',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'units',\n",
       " 'unroll',\n",
       " 'updates',\n",
       " 'use_bias',\n",
       " 'variable_dtype',\n",
       " 'variables',\n",
       " 'weights',\n",
       " 'with_name_scope',\n",
       " 'zero_output_for_mask']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in dir(simpleRNN_layer) if not s.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d388da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleRNN_layer.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b0442c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleRNN_layer.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f85eacf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleRNN_layer.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9287b222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleRNN_layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba979b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleRNN_layer.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de2813b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'simple_rnn',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (None, None, 11),\n",
       " 'dtype': 'float32',\n",
       " 'return_sequences': False,\n",
       " 'return_state': False,\n",
       " 'go_backwards': False,\n",
       " 'stateful': False,\n",
       " 'unroll': False,\n",
       " 'time_major': False,\n",
       " 'units': 5,\n",
       " 'activation': 'tanh',\n",
       " 'use_bias': True,\n",
       " 'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "  'config': {'seed': None}},\n",
       " 'recurrent_initializer': {'class_name': 'Orthogonal',\n",
       "  'config': {'gain': 1.0, 'seed': None}},\n",
       " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       " 'kernel_regularizer': None,\n",
       " 'recurrent_regularizer': None,\n",
       " 'bias_regularizer': None,\n",
       " 'activity_regularizer': None,\n",
       " 'kernel_constraint': None,\n",
       " 'recurrent_constraint': None,\n",
       " 'bias_constraint': None,\n",
       " 'dropout': 0.0,\n",
       " 'recurrent_dropout': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleRNN_layer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4d88167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleRNN_layer.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bcf295",
   "metadata": {},
   "source": [
    "It seems that we can only get the trainable parameters after including the layer in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cb0c986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-13 10:53:36.546775: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-13 10:53:36.546909: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-13 10:53:36.547033: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mushroom-x200): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([simpleRNN_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb5ee282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives pretty much the same attributes as above\n",
    "#[s for s in dir(model.layers[0]) if not s.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11fde28",
   "metadata": {},
   "source": [
    "The attributes\n",
    "\n",
    "- `weights`\n",
    "- `trainable_weigths`\n",
    "- `variables`\n",
    "- `trainable_variables`\n",
    "\n",
    "all gives the same list of `[W_x, W_y, b]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83bbb489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'simple_rnn/simple_rnn_cell/kernel:0' shape=(11, 5) dtype=float32, numpy=\n",
       " array([[-0.39205524,  0.6056785 ,  0.00976646,  0.2922976 , -0.54178315],\n",
       "        [ 0.58913845, -0.40885615, -0.06774998,  0.17361706,  0.06441653],\n",
       "        [-0.39094067, -0.11464536, -0.39618343, -0.2597798 , -0.42601216],\n",
       "        [-0.48977983,  0.5518094 , -0.54704314,  0.32235378, -0.48730862],\n",
       "        [-0.6051304 ,  0.36912167, -0.3797627 , -0.05026609,  0.0447852 ],\n",
       "        [ 0.12057722, -0.4491092 ,  0.5895316 , -0.4219625 ,  0.06617713],\n",
       "        [-0.6115918 ,  0.04476041,  0.38420504, -0.16691211, -0.04666221],\n",
       "        [-0.25456628, -0.1030075 ,  0.5951409 ,  0.1744259 ,  0.4264763 ],\n",
       "        [ 0.05671275,  0.43728095,  0.35596383,  0.50579876, -0.33917367],\n",
       "        [-0.35362354, -0.2584312 ,  0.45808452, -0.12331593,  0.0307436 ],\n",
       "        [-0.50871116, -0.11249492,  0.36809516,  0.2002685 , -0.3210538 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'simple_rnn/simple_rnn_cell/recurrent_kernel:0' shape=(5, 5) dtype=float32, numpy=\n",
       " array([[-0.21763706,  0.06546668,  0.7511529 ,  0.619652  , -0.01220071],\n",
       "        [-0.36351594, -0.8713754 , -0.05070263,  0.01944964, -0.32498005],\n",
       "        [ 0.6880631 , -0.47425818,  0.30692726, -0.07143533,  0.44982335],\n",
       "        [-0.37888932, -0.10204748, -0.36526978,  0.33574256,  0.77452195],\n",
       "        [ 0.45111242, -0.03293195, -0.45340055,  0.7055686 , -0.30333793]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'simple_rnn/simple_rnn_cell/bias:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71f62faf",
   "metadata": {},
   "source": [
    "model.layers[0].variables"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ad9ea90",
   "metadata": {},
   "source": [
    "model.layers[0].trainable_weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7aea5e85",
   "metadata": {},
   "source": [
    "model.layers[0].trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d43b25",
   "metadata": {},
   "source": [
    "The method `get_weights()` gives pretty much the same list but with members as `np.ndarray` rather than `tf.Variable`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18725412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.39205524,  0.6056785 ,  0.00976646,  0.2922976 , -0.54178315],\n",
       "        [ 0.58913845, -0.40885615, -0.06774998,  0.17361706,  0.06441653],\n",
       "        [-0.39094067, -0.11464536, -0.39618343, -0.2597798 , -0.42601216],\n",
       "        [-0.48977983,  0.5518094 , -0.54704314,  0.32235378, -0.48730862],\n",
       "        [-0.6051304 ,  0.36912167, -0.3797627 , -0.05026609,  0.0447852 ],\n",
       "        [ 0.12057722, -0.4491092 ,  0.5895316 , -0.4219625 ,  0.06617713],\n",
       "        [-0.6115918 ,  0.04476041,  0.38420504, -0.16691211, -0.04666221],\n",
       "        [-0.25456628, -0.1030075 ,  0.5951409 ,  0.1744259 ,  0.4264763 ],\n",
       "        [ 0.05671275,  0.43728095,  0.35596383,  0.50579876, -0.33917367],\n",
       "        [-0.35362354, -0.2584312 ,  0.45808452, -0.12331593,  0.0307436 ],\n",
       "        [-0.50871116, -0.11249492,  0.36809516,  0.2002685 , -0.3210538 ]],\n",
       "       dtype=float32),\n",
       " array([[-0.21763706,  0.06546668,  0.7511529 ,  0.619652  , -0.01220071],\n",
       "        [-0.36351594, -0.8713754 , -0.05070263,  0.01944964, -0.32498005],\n",
       "        [ 0.6880631 , -0.47425818,  0.30692726, -0.07143533,  0.44982335],\n",
       "        [-0.37888932, -0.10204748, -0.36526978,  0.33574256,  0.77452195],\n",
       "        [ 0.45111242, -0.03293195, -0.45340055,  0.7055686 , -0.30333793]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6910969",
   "metadata": {},
   "source": [
    "There are even `non_trainable_variables` and `non_trainable_weights` attributes. But in this case they consists of nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "550a8800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].non_trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f23d9982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].non_trainable_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e5b93",
   "metadata": {},
   "source": [
    "**(?)** Why must we put the layer into a model before being able to inspect its weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c104c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1695353f",
   "metadata": {},
   "source": [
    "## Memory Cells\n",
    "In a more sophisticated setting, there is also sth called **hidden state**, usually noted as $\\mathbf{h}_{(t)}\\,.$\n",
    "And the common practice is\n",
    "\n",
    "- let $\\mathbf{h}_{(t)} = f(\\mathbf{h}_{(t-1)}\\,, \\mathbf{x}_{(t)}\\,)$ for some function $f$\n",
    "- let $\\mathbf{y}_{(t)} = g(\\mathbf{h}_{(t-1)}\\,, \\mathbf{x}_{(t)}\\,)$ for some function $g$.\n",
    "\n",
    "In what we discussed above (for the simplest case), the output $\\mathbf{y}_{(t)}$ plays the role of a hidden state $\\mathbf{h}_{(t)}$ and there was no $\\mathbf{h}_{(t)}$. But further in this chapter, we will encounter more sophisticated RNNs which do make use of hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee51de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35d8731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
